{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced options for multioutput handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from py_boost import GradientBoosting, SketchBoost\n",
    "\n",
    "# strategies to deal with multiple outputs\n",
    "from py_boost.multioutput.sketching import *\n",
    "from py_boost.multioutput.target_splitter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data from OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-20 14:27:27--  https://www.openml.org/data/get_csv/19335692/file1c556677f875.csv\n",
      "Resolving www.openml.org (www.openml.org)... 131.155.11.11\n",
      "Connecting to www.openml.org (www.openml.org)|131.155.11.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
      "Location: https://api.openml.org/data/get_csv/19335692/file1c556677f875.csv [following]\n",
      "--2023-03-20 14:27:27--  https://api.openml.org/data/get_csv/19335692/file1c556677f875.csv\n",
      "Resolving api.openml.org (api.openml.org)... 131.155.11.11\n",
      "Connecting to api.openml.org (api.openml.org)|131.155.11.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘../data/helena.csv’\n",
      "\n",
      "../data/helena.csv      [      <=>           ]  14.56M  11.5MB/s    in 1.3s    \n",
      "\n",
      "2023-03-20 14:27:28 (11.5 MB/s) - ‘../data/helena.csv’ saved [15271704]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.openml.org/data/get_csv/19335692/file1c556677f875.csv -O ../data/helena.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.080556</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.490822</td>\n",
       "      <td>0.586406</td>\n",
       "      <td>0.066414</td>\n",
       "      <td>0.092206</td>\n",
       "      <td>0.116352</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342986</td>\n",
       "      <td>78.6894</td>\n",
       "      <td>17.237800</td>\n",
       "      <td>21.504200</td>\n",
       "      <td>14.43730</td>\n",
       "      <td>17.378000</td>\n",
       "      <td>9.61674</td>\n",
       "      <td>-0.609370</td>\n",
       "      <td>1.044830</td>\n",
       "      <td>1.481790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>0.049398</td>\n",
       "      <td>0.147917</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.542865</td>\n",
       "      <td>0.515608</td>\n",
       "      <td>0.105128</td>\n",
       "      <td>0.475550</td>\n",
       "      <td>0.049555</td>\n",
       "      <td>0.383460</td>\n",
       "      <td>...</td>\n",
       "      <td>2.639370</td>\n",
       "      <td>59.7879</td>\n",
       "      <td>5.393410</td>\n",
       "      <td>3.819610</td>\n",
       "      <td>11.49240</td>\n",
       "      <td>3.929470</td>\n",
       "      <td>5.91423</td>\n",
       "      <td>1.409210</td>\n",
       "      <td>4.749540</td>\n",
       "      <td>1.103820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0.548663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397029</td>\n",
       "      <td>0.627398</td>\n",
       "      <td>1.023440</td>\n",
       "      <td>1.004220</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>0.451337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137427</td>\n",
       "      <td>58.1429</td>\n",
       "      <td>-3.365980</td>\n",
       "      <td>-0.037489</td>\n",
       "      <td>10.63470</td>\n",
       "      <td>2.660180</td>\n",
       "      <td>3.93377</td>\n",
       "      <td>-0.898220</td>\n",
       "      <td>2.137790</td>\n",
       "      <td>1.054470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0.023073</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>0.622998</td>\n",
       "      <td>0.764067</td>\n",
       "      <td>0.202599</td>\n",
       "      <td>0.177892</td>\n",
       "      <td>0.071232</td>\n",
       "      <td>0.531712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477009</td>\n",
       "      <td>55.4798</td>\n",
       "      <td>-1.051090</td>\n",
       "      <td>-4.755360</td>\n",
       "      <td>13.36710</td>\n",
       "      <td>2.852060</td>\n",
       "      <td>9.65162</td>\n",
       "      <td>0.224397</td>\n",
       "      <td>-0.220216</td>\n",
       "      <td>-0.273287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>0.224427</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.902083</td>\n",
       "      <td>0.814199</td>\n",
       "      <td>0.576879</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.822975</td>\n",
       "      <td>0.026121</td>\n",
       "      <td>0.425875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521306</td>\n",
       "      <td>76.8475</td>\n",
       "      <td>-19.371700</td>\n",
       "      <td>32.270700</td>\n",
       "      <td>9.41442</td>\n",
       "      <td>4.343450</td>\n",
       "      <td>8.67710</td>\n",
       "      <td>-1.587580</td>\n",
       "      <td>1.117870</td>\n",
       "      <td>-0.545338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65191</th>\n",
       "      <td>88</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.152083</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.114431</td>\n",
       "      <td>0.406104</td>\n",
       "      <td>0.143170</td>\n",
       "      <td>0.053086</td>\n",
       "      <td>0.129365</td>\n",
       "      <td>0.215442</td>\n",
       "      <td>...</td>\n",
       "      <td>1.265300</td>\n",
       "      <td>53.2951</td>\n",
       "      <td>-1.416430</td>\n",
       "      <td>2.173900</td>\n",
       "      <td>13.66950</td>\n",
       "      <td>1.588520</td>\n",
       "      <td>2.02855</td>\n",
       "      <td>0.619052</td>\n",
       "      <td>0.622377</td>\n",
       "      <td>-0.363035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65192</th>\n",
       "      <td>77</td>\n",
       "      <td>0.411279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.503805</td>\n",
       "      <td>0.207163</td>\n",
       "      <td>1.003740</td>\n",
       "      <td>0.412067</td>\n",
       "      <td>0.017673</td>\n",
       "      <td>0.044771</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.842380</td>\n",
       "      <td>91.1178</td>\n",
       "      <td>-0.009207</td>\n",
       "      <td>-2.224830</td>\n",
       "      <td>1.30504</td>\n",
       "      <td>0.898489</td>\n",
       "      <td>1.80362</td>\n",
       "      <td>-2.726140</td>\n",
       "      <td>-0.184329</td>\n",
       "      <td>-0.476441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65193</th>\n",
       "      <td>71</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501360</td>\n",
       "      <td>0.501075</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213472</td>\n",
       "      <td>84.4141</td>\n",
       "      <td>2.042450</td>\n",
       "      <td>13.849800</td>\n",
       "      <td>7.24428</td>\n",
       "      <td>1.443890</td>\n",
       "      <td>4.00495</td>\n",
       "      <td>-0.749115</td>\n",
       "      <td>1.025130</td>\n",
       "      <td>0.096257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65194</th>\n",
       "      <td>24</td>\n",
       "      <td>0.206175</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.749915</td>\n",
       "      <td>0.550936</td>\n",
       "      <td>0.292477</td>\n",
       "      <td>0.830921</td>\n",
       "      <td>0.033542</td>\n",
       "      <td>0.430515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879472</td>\n",
       "      <td>61.4110</td>\n",
       "      <td>17.354200</td>\n",
       "      <td>5.566660</td>\n",
       "      <td>16.22600</td>\n",
       "      <td>10.049400</td>\n",
       "      <td>6.04195</td>\n",
       "      <td>0.400956</td>\n",
       "      <td>0.375599</td>\n",
       "      <td>0.644575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65195</th>\n",
       "      <td>9</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.844969</td>\n",
       "      <td>0.054704</td>\n",
       "      <td>0.091855</td>\n",
       "      <td>0.052645</td>\n",
       "      <td>0.192523</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.676500</td>\n",
       "      <td>93.1596</td>\n",
       "      <td>0.559074</td>\n",
       "      <td>-0.852947</td>\n",
       "      <td>8.30315</td>\n",
       "      <td>1.215720</td>\n",
       "      <td>1.28395</td>\n",
       "      <td>-1.889180</td>\n",
       "      <td>2.350320</td>\n",
       "      <td>0.179997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65196 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class        V1        V2        V3        V4        V5        V6  \\\n",
       "0         41  0.005521  0.080556  0.110417  0.490822  0.586406  0.066414   \n",
       "1         92  0.049398  0.147917  0.541667  0.542865  0.515608  0.105128   \n",
       "2         24  0.548663  1.000000  1.000000  0.397029  0.627398  1.023440   \n",
       "3         29  0.023073  0.206250  0.238889  0.622998  0.764067  0.202599   \n",
       "4         91  0.224427  0.433333  0.902083  0.814199  0.576879  0.344413   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "65191     88  0.007292  0.152083  0.061111  0.114431  0.406104  0.143170   \n",
       "65192     77  0.411279  1.000000  0.430556  0.503805  0.207163  1.003740   \n",
       "65193     71  0.999352  1.000000  1.000000  0.501360  0.501075  0.999384   \n",
       "65194     24  0.206175  0.383333  0.944444  0.749915  0.550936  0.292477   \n",
       "65195      9  0.003096  0.102083  0.066667  0.844969  0.054704  0.091855   \n",
       "\n",
       "             V7        V8        V9  ...       V18      V19        V20  \\\n",
       "0      0.092206  0.116352  0.379310  ... -0.342986  78.6894  17.237800   \n",
       "1      0.475550  0.049555  0.383460  ...  2.639370  59.7879   5.393410   \n",
       "2      1.004220  0.027381  0.451337  ...  0.137427  58.1429  -3.365980   \n",
       "3      0.177892  0.071232  0.531712  ...  0.477009  55.4798  -1.051090   \n",
       "4      0.822975  0.026121  0.425875  ...  0.521306  76.8475 -19.371700   \n",
       "...         ...       ...       ...  ...       ...      ...        ...   \n",
       "65191  0.053086  0.129365  0.215442  ...  1.265300  53.2951  -1.416430   \n",
       "65192  0.412067  0.017673  0.044771  ... -2.842380  91.1178  -0.009207   \n",
       "65193  0.999414  0.009636  0.000648  ...  0.213472  84.4141   2.042450   \n",
       "65194  0.830921  0.033542  0.430515  ...  0.879472  61.4110  17.354200   \n",
       "65195  0.052645  0.192523  0.545068  ... -1.676500  93.1596   0.559074   \n",
       "\n",
       "             V21       V22        V23      V24       V25       V26       V27  \n",
       "0      21.504200  14.43730  17.378000  9.61674 -0.609370  1.044830  1.481790  \n",
       "1       3.819610  11.49240   3.929470  5.91423  1.409210  4.749540  1.103820  \n",
       "2      -0.037489  10.63470   2.660180  3.93377 -0.898220  2.137790  1.054470  \n",
       "3      -4.755360  13.36710   2.852060  9.65162  0.224397 -0.220216 -0.273287  \n",
       "4      32.270700   9.41442   4.343450  8.67710 -1.587580  1.117870 -0.545338  \n",
       "...          ...       ...        ...      ...       ...       ...       ...  \n",
       "65191   2.173900  13.66950   1.588520  2.02855  0.619052  0.622377 -0.363035  \n",
       "65192  -2.224830   1.30504   0.898489  1.80362 -2.726140 -0.184329 -0.476441  \n",
       "65193  13.849800   7.24428   1.443890  4.00495 -0.749115  1.025130  0.096257  \n",
       "65194   5.566660  16.22600  10.049400  6.04195  0.400956  0.375599  0.644575  \n",
       "65195  -0.852947   8.30315   1.215720  1.28395 -1.889180  2.350320  0.179997  \n",
       "\n",
       "[65196 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/helena.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78    4005\n",
       "55    3063\n",
       "40    2992\n",
       "39    2623\n",
       "38    2216\n",
       "      ... \n",
       "75     121\n",
       "56     121\n",
       "32     119\n",
       "34     116\n",
       "10     111\n",
       "Name: class, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have 100 classes here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('class', axis=1).values.astype('float32')\n",
    "y = data['class'].values.astype('int32')\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traininig a multiclass model\n",
    "\n",
    "A simple use case for training a multiclass problem is the same as for regression. By default py_boost builds multioutout trees to handle multioutput problems (single tree outputs a vector of length 100 for 100 class task).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:27:34] Stdout logging level is INFO.\n",
      "[14:27:34] GDBT train starts. Max iter 10000, early stopping rounds 300\n",
      "[14:27:35] Iter 0; Sample 0, Crossentropy = 4.285501684682705; \n",
      "[14:27:42] Iter 100; Sample 0, Crossentropy = 2.7763018474667405; \n",
      "[14:27:49] Iter 200; Sample 0, Crossentropy = 2.6534368930852343; \n",
      "[14:27:57] Iter 300; Sample 0, Crossentropy = 2.6120720412816; \n",
      "[14:28:05] Iter 400; Sample 0, Crossentropy = 2.591461281805933; \n",
      "[14:28:14] Iter 500; Sample 0, Crossentropy = 2.5793298777967135; \n",
      "[14:28:22] Iter 600; Sample 0, Crossentropy = 2.5728810045047528; \n",
      "[14:28:31] Iter 700; Sample 0, Crossentropy = 2.5679381462019157; \n",
      "[14:28:40] Iter 800; Sample 0, Crossentropy = 2.56521209757055; \n",
      "[14:28:49] Iter 900; Sample 0, Crossentropy = 2.563091753755386; \n",
      "[14:28:57] Iter 1000; Sample 0, Crossentropy = 2.5616368979225217; \n",
      "[14:29:06] Iter 1100; Sample 0, Crossentropy = 2.5606824117112787; \n",
      "[14:29:15] Iter 1200; Sample 0, Crossentropy = 2.5603412056454866; \n",
      "[14:29:23] Iter 1300; Sample 0, Crossentropy = 2.5595679772313256; \n",
      "[14:29:32] Iter 1400; Sample 0, Crossentropy = 2.55978110052935; \n",
      "[14:29:40] Iter 1500; Sample 0, Crossentropy = 2.5605681307499433; \n",
      "[14:29:48] Iter 1600; Sample 0, Crossentropy = 2.5614285169155626; \n",
      "[14:29:51] Early stopping at iter 1630, best iter 1330, best_score 2.5594445778766413\n",
      "CPU times: user 2min, sys: 23.1 s, total: 2min 23s\n",
      "Wall time: 2min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f438d0259d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting(\n",
    "    'crossentropy',\n",
    "     ntrees=10000, lr=0.03, verbose=100, es=300, lambda_l2=1, gd_steps=1,\n",
    "     subsample=1, colsample=1, min_data_in_leaf=10, use_hess=True,\n",
    "     max_bin=256, max_depth=6, debug=True\n",
    ")\n",
    "\n",
    "model.fit(X, y, \n",
    "          eval_sets = [{'X': X_test, 'y': y_test}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 67.9 ms, total: 1.2 s\n",
      "Wall time: 1.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13040, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred = model.predict(X_test)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sketching strategies to speedup training\n",
    "\n",
    "Computational costs of training multioutput models drastically increase when number of output grows. We implemented a few strategies to simplify tree structure search via gradinet matrix sketching:\n",
    "\n",
    "* ***RandomSamplingSketch*** (recommended for use_hess=True)\n",
    "* ***RandomProjectionSketch*** (recommended for use_hess=False)\n",
    "* ***TopOutputsSketch***\n",
    "* ***SVDSketch*** (needs RAPIDS (cuml) to be installed)\n",
    "\n",
    "Let us check, how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:52] Stdout logging level is INFO.\n",
      "[14:29:52] GDBT train starts. Max iter 10000, early stopping rounds 300\n",
      "[14:29:53] Iter 0; Sample 0, Crossentropy = 4.37780858910313; \n",
      "[14:29:54] Iter 100; Sample 0, Crossentropy = 2.8830431798283946; \n",
      "[14:29:55] Iter 200; Sample 0, Crossentropy = 2.7344265194452593; \n",
      "[14:29:56] Iter 300; Sample 0, Crossentropy = 2.6735993342291535; \n",
      "[14:29:58] Iter 400; Sample 0, Crossentropy = 2.639656949046086; \n",
      "[14:29:59] Iter 500; Sample 0, Crossentropy = 2.616071220871295; \n",
      "[14:30:00] Iter 600; Sample 0, Crossentropy = 2.599227755788996; \n",
      "[14:30:01] Iter 700; Sample 0, Crossentropy = 2.58695941504371; \n",
      "[14:30:03] Iter 800; Sample 0, Crossentropy = 2.577093448514365; \n",
      "[14:30:04] Iter 900; Sample 0, Crossentropy = 2.5705359899350455; \n",
      "[14:30:05] Iter 1000; Sample 0, Crossentropy = 2.5652103670154838; \n",
      "[14:30:06] Iter 1100; Sample 0, Crossentropy = 2.5596293871441924; \n",
      "[14:30:07] Iter 1200; Sample 0, Crossentropy = 2.5561329785264295; \n",
      "[14:30:09] Iter 1300; Sample 0, Crossentropy = 2.552509484042676; \n",
      "[14:30:10] Iter 1400; Sample 0, Crossentropy = 2.5496870255211794; \n",
      "[14:30:11] Iter 1500; Sample 0, Crossentropy = 2.5468310754874772; \n",
      "[14:30:12] Iter 1600; Sample 0, Crossentropy = 2.544790700562412; \n",
      "[14:30:14] Iter 1700; Sample 0, Crossentropy = 2.543777952591995; \n",
      "[14:30:15] Iter 1800; Sample 0, Crossentropy = 2.5428519230479125; \n",
      "[14:30:16] Iter 1900; Sample 0, Crossentropy = 2.5417947004973303; \n",
      "[14:30:17] Iter 2000; Sample 0, Crossentropy = 2.5410049197365367; \n",
      "[14:30:19] Iter 2100; Sample 0, Crossentropy = 2.5411121637689247; \n",
      "[14:30:20] Iter 2200; Sample 0, Crossentropy = 2.540880479843611; \n",
      "[14:30:21] Iter 2300; Sample 0, Crossentropy = 2.5409935084024067; \n",
      "[14:30:22] Iter 2400; Sample 0, Crossentropy = 2.541161387010354; \n",
      "[14:30:23] Early stopping at iter 2479, best iter 2179, best_score 2.5407851558009598\n",
      "CPU times: user 31.2 s, sys: 684 ms, total: 31.9 s\n",
      "Wall time: 31.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f435ec0d940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sketch = RandomProjectionSketch(1)\n",
    "# sketch = RandomSamplingSketch(10)\n",
    "# sketch = TopOutputsSketch(10)\n",
    "# sketch = SVDSketch(n_components=1)\n",
    "\n",
    "model = GradientBoosting(\n",
    "    'crossentropy',\n",
    "    ntrees=10000, lr=0.03, verbose=100, es=300, lambda_l2=1, gd_steps=1, \n",
    "    subsample=1, colsample=1, min_data_in_leaf=10, use_hess=False, \n",
    "    max_bin=256, max_depth=6,\n",
    "    multioutput_sketch=sketch, debug=True\n",
    ")\n",
    "\n",
    "model.fit(X, y, eval_sets = [{'X': X_test, 'y': y_test}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.76 s, sys: 76.1 ms, total: 1.84 s\n",
      "Wall time: 1.84 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13040, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred = model.predict(X_test)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SketchBoost\n",
    "\n",
    "Alternatively you can use SketchBoost class with built in sketching strateges. Just define number of outputs to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:25] Stdout logging level is INFO.\n",
      "[14:30:25] GDBT train starts. Max iter 10000, early stopping rounds 300\n",
      "[14:30:25] Iter 0; Sample 0, Crossentropy = 4.373896924422614; \n",
      "[14:30:27] Iter 100; Sample 0, Crossentropy = 2.907183459675343; \n",
      "[14:30:28] Iter 200; Sample 0, Crossentropy = 2.751375678378877; \n",
      "[14:30:29] Iter 300; Sample 0, Crossentropy = 2.689612458132744; \n",
      "[14:30:30] Iter 400; Sample 0, Crossentropy = 2.6544527823729394; \n",
      "[14:30:32] Iter 500; Sample 0, Crossentropy = 2.6289818069997537; \n",
      "[14:30:33] Iter 600; Sample 0, Crossentropy = 2.6110374028609233; \n",
      "[14:30:34] Iter 700; Sample 0, Crossentropy = 2.59649351120474; \n",
      "[14:30:35] Iter 800; Sample 0, Crossentropy = 2.58602262416369; \n",
      "[14:30:37] Iter 900; Sample 0, Crossentropy = 2.577047973870354; \n",
      "[14:30:38] Iter 1000; Sample 0, Crossentropy = 2.5710195922726817; \n",
      "[14:30:39] Iter 1100; Sample 0, Crossentropy = 2.565049627730205; \n",
      "[14:30:40] Iter 1200; Sample 0, Crossentropy = 2.5607273376650648; \n",
      "[14:30:42] Iter 1300; Sample 0, Crossentropy = 2.556881997816994; \n",
      "[14:30:43] Iter 1400; Sample 0, Crossentropy = 2.5534663656568783; \n",
      "[14:30:44] Iter 1500; Sample 0, Crossentropy = 2.550835986110502; \n",
      "[14:30:45] Iter 1600; Sample 0, Crossentropy = 2.5481310427657213; \n",
      "[14:30:47] Iter 1700; Sample 0, Crossentropy = 2.5460950302319523; \n",
      "[14:30:48] Iter 1800; Sample 0, Crossentropy = 2.544253291631499; \n",
      "[14:30:49] Iter 1900; Sample 0, Crossentropy = 2.542613335086523; \n",
      "[14:30:51] Iter 2000; Sample 0, Crossentropy = 2.54213326853868; \n",
      "[14:30:52] Iter 2100; Sample 0, Crossentropy = 2.5415010213253377; \n",
      "[14:30:54] Iter 2200; Sample 0, Crossentropy = 2.54132030299322; \n",
      "[14:30:55] Iter 2300; Sample 0, Crossentropy = 2.5411189011253916; \n",
      "[14:30:57] Iter 2400; Sample 0, Crossentropy = 2.541399924000807; \n",
      "[14:30:58] Iter 2500; Sample 0, Crossentropy = 2.541988421720829; \n",
      "[14:30:59] Early stopping at iter 2582, best iter 2282, best_score 2.54101817817702\n",
      "CPU times: user 34.3 s, sys: 842 ms, total: 35.1 s\n",
      "Wall time: 34.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.sketch_boost.SketchBoost at 0x7f438ce5b820>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = SketchBoost(\n",
    "    'crossentropy',\n",
    "     ntrees=10000, lr=0.03, verbose=100, es=300, lambda_l2=1, gd_steps=1, \n",
    "     subsample=1, colsample=1, min_data_in_leaf=10, \n",
    "     max_bin=256, max_depth=6,\n",
    ")\n",
    "\n",
    "model.fit(X, y, eval_sets = [{'X': X_test, 'y': y_test}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.06 s, sys: 36.1 ms, total: 1.1 s\n",
      "Wall time: 1.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13040, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred = model.predict(X_test)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see a nice speed up and sometimes even a better accuracy!\n",
    "\n",
    "#### These modifications allow us to train a model faster than CatBoost does (with a similar setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4.2940505\ttest: 4.3045904\tbest: 4.3045904 (0)\ttotal: 42.5ms\tremaining: 7m 4s\n",
      "100:\tlearn: 2.7026067\ttest: 2.8639825\tbest: 2.8639825 (100)\ttotal: 3.59s\tremaining: 5m 51s\n",
      "200:\tlearn: 2.4526129\ttest: 2.7287550\tbest: 2.7287550 (200)\ttotal: 6.96s\tremaining: 5m 39s\n",
      "300:\tlearn: 2.3213712\ttest: 2.6789284\tbest: 2.6789284 (300)\ttotal: 10.2s\tremaining: 5m 27s\n",
      "400:\tlearn: 2.2232472\ttest: 2.6516266\tbest: 2.6516266 (400)\ttotal: 13.3s\tremaining: 5m 17s\n",
      "500:\tlearn: 2.1449561\ttest: 2.6351179\tbest: 2.6351179 (500)\ttotal: 16.3s\tremaining: 5m 9s\n",
      "600:\tlearn: 2.0773086\ttest: 2.6237371\tbest: 2.6237371 (600)\ttotal: 19.3s\tremaining: 5m 2s\n",
      "700:\tlearn: 2.0146061\ttest: 2.6149348\tbest: 2.6149321 (699)\ttotal: 22.3s\tremaining: 4m 55s\n",
      "800:\tlearn: 1.9531141\ttest: 2.6072940\tbest: 2.6072838 (799)\ttotal: 25.3s\tremaining: 4m 50s\n",
      "900:\tlearn: 1.8969740\ttest: 2.6016194\tbest: 2.6016194 (900)\ttotal: 28.3s\tremaining: 4m 46s\n",
      "1000:\tlearn: 1.8410810\ttest: 2.5963373\tbest: 2.5963373 (1000)\ttotal: 31.3s\tremaining: 4m 41s\n",
      "1100:\tlearn: 1.7884030\ttest: 2.5926045\tbest: 2.5926045 (1100)\ttotal: 34.3s\tremaining: 4m 37s\n",
      "1200:\tlearn: 1.7363573\ttest: 2.5891227\tbest: 2.5891227 (1200)\ttotal: 37.3s\tremaining: 4m 33s\n",
      "1300:\tlearn: 1.6876309\ttest: 2.5862323\tbest: 2.5862323 (1300)\ttotal: 40.3s\tremaining: 4m 29s\n",
      "1400:\tlearn: 1.6391251\ttest: 2.5840856\tbest: 2.5840494 (1399)\ttotal: 43.3s\tremaining: 4m 25s\n",
      "1500:\tlearn: 1.5954443\ttest: 2.5822580\tbest: 2.5822580 (1500)\ttotal: 46.3s\tremaining: 4m 21s\n",
      "1600:\tlearn: 1.5487276\ttest: 2.5805574\tbest: 2.5805143 (1596)\ttotal: 49.3s\tremaining: 4m 18s\n",
      "1700:\tlearn: 1.5048335\ttest: 2.5793175\tbest: 2.5793175 (1700)\ttotal: 52.2s\tremaining: 4m 14s\n",
      "1800:\tlearn: 1.4619290\ttest: 2.5782484\tbest: 2.5781927 (1796)\ttotal: 55.2s\tremaining: 4m 11s\n",
      "1900:\tlearn: 1.4215628\ttest: 2.5770454\tbest: 2.5770088 (1895)\ttotal: 58.2s\tremaining: 4m 7s\n",
      "2000:\tlearn: 1.3810519\ttest: 2.5762944\tbest: 2.5762944 (2000)\ttotal: 1m 1s\tremaining: 4m 4s\n",
      "2100:\tlearn: 1.3412728\ttest: 2.5753265\tbest: 2.5753265 (2100)\ttotal: 1m 4s\tremaining: 4m 1s\n",
      "2200:\tlearn: 1.3069092\ttest: 2.5754080\tbest: 2.5752645 (2111)\ttotal: 1m 7s\tremaining: 3m 57s\n",
      "2300:\tlearn: 1.2680846\ttest: 2.5749536\tbest: 2.5749101 (2292)\ttotal: 1m 10s\tremaining: 3m 54s\n",
      "2400:\tlearn: 1.2329422\ttest: 2.5745540\tbest: 2.5745090 (2393)\ttotal: 1m 13s\tremaining: 3m 51s\n",
      "2500:\tlearn: 1.1996895\ttest: 2.5750623\tbest: 2.5744347 (2440)\ttotal: 1m 16s\tremaining: 3m 48s\n",
      "2600:\tlearn: 1.1656659\ttest: 2.5749584\tbest: 2.5744347 (2440)\ttotal: 1m 19s\tremaining: 3m 45s\n",
      "2700:\tlearn: 1.1336638\ttest: 2.5751603\tbest: 2.5744347 (2440)\ttotal: 1m 22s\tremaining: 3m 41s\n",
      "bestTest = 2.574434732\n",
      "bestIteration = 2440\n",
      "Shrink model to first 2441 iterations.\n",
      "CPU times: user 3min 9s, sys: 42.4 s, total: 3min 51s\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f43613fc9d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "                       grow_policy='Depthwise', \n",
    "                       bootstrap_type='Bernoulli',\n",
    "                       subsample=1.,\n",
    "                       border_count=256, \n",
    "                       iterations=10000, \n",
    "                       od_wait=300,\n",
    "                       max_depth=6, \n",
    "                       devices='0:0', \n",
    "                       learning_rate=0.03, \n",
    "                       l2_leaf_reg=1, \n",
    "                       min_data_in_leaf=10, \n",
    "                       score_function='L2',\n",
    "                       model_shrink_mode='Constant',\n",
    "                       **{'task_type': 'GPU', 'verbose': 100, }\n",
    "                    )\n",
    "\n",
    "model.fit(X, y, eval_set = (X_test, y_test))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.06",
   "language": "python",
   "name": "rapids-22.06"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
